import cv2
import numpy as np
import math
import time


def preprocess_frame(frame):
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    yellow_mask = cv2.inRange(hsv, (15, 30, 80), (40, 255, 255))

    h, s, v = cv2.split(hsv)
    s = cv2.equalizeHist(s)
    v = cv2.equalizeHist(v)
    boosted_hsv = cv2.merge([h, s, v])
    boosted_bgr = cv2.cvtColor(boosted_hsv, cv2.COLOR_HSV2BGR)
    boosted_gray = cv2.cvtColor(boosted_bgr, cv2.COLOR_BGR2GRAY)

    masked_gray = cv2.bitwise_and(boosted_gray, boosted_gray, mask=yellow_mask)
    adaptive_thresh = cv2.adaptiveThreshold(masked_gray, 255,
                                            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                            cv2.THRESH_BINARY, 11, 2)

    kernel = np.ones((5, 5), np.uint8)
    cleaned = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_OPEN, kernel)

    return cleaned, boosted_gray


def detect_traffic_light(frame):
    height, width = frame.shape[:2]
    roi = frame[0:int(height * 0.3), 0:int(width * 0.3)]

    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    lower_red1 = np.array([0, 70, 50])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([160, 70, 50])
    upper_red2 = np.array([180, 255, 255])

    lower_green = np.array([40, 40, 40])
    upper_green = np.array([90, 255, 255])

    lower_yellow = np.array([15, 50, 50])
    upper_yellow = np.array([35, 255, 255])

    mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask_red = cv2.bitwise_or(mask_red1, mask_red2)

    mask_green = cv2.inRange(hsv, lower_green, upper_green)
    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)

    all_masks = [mask_red, mask_green, mask_yellow]
    traffic_light_status = "NO TRAFFIC LIGHT"

    for mask in all_masks:
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 1000:
                x, y, w, h = cv2.boundingRect(contour)

                aspect_ratio = float(w) / float(h)
                if 0.8 < aspect_ratio < 1.2:
                    roi_rect = frame[y:y + h, x:x + w]
                    rect_gray = cv2.cvtColor(roi_rect, cv2.COLOR_BGR2GRAY)
                    _, thresholded = cv2.threshold(rect_gray, 100, 255, cv2.THRESH_BINARY)

                    border_pixels = thresholded[0:5, :]
                    bottom_pixels = thresholded[-5:, :]
                    left_pixels = thresholded[:, 0:5]
                    right_pixels = thresholded[:, -5:]

                    border_black = np.count_nonzero(border_pixels == 0) > 0 or \
                                   np.count_nonzero(bottom_pixels == 0) > 0 or \
                                   np.count_nonzero(left_pixels == 0) > 0 or \
                                   np.count_nonzero(right_pixels == 0) > 0

                    if border_black:
                        if np.count_nonzero(mask) > 1000:
                            if np.count_nonzero(mask_red) > 1000:
                                traffic_light_status = "RED (STOP)"
                            elif np.count_nonzero(mask_green) > 1000:
                                traffic_light_status = "GREEN (MOVE)"
                            elif np.count_nonzero(mask_yellow) > 1000:
                                traffic_light_status = "YELLOW (Be Ready)"
                            break
                else:
                    traffic_light_status = "NO TRAFFIC LIGHT"

    return traffic_light_status


def create_road_mask(frame,lane_lines):
    height, width = frame.shape[:2]  # get the height and width of the frame
    mask = np.zeros((height, width), dtype=np.uint8)  # initialize an empty black mask of the same size as the frame
    if lane_lines:  # if lane lines are detected
        # define a tighter road region based on the lane points
        min_y = int(height * 0.5)  # set the minimum y-coordinate for the road region (half the height of the frame)
        max_y = height  # set the maximum y-coordinate for the road region (full height of the frame)

        min_x = min(pt[0] for pt in lane_lines)  # get the minimum x-coordinate from the lane points
        max_x = max(pt[0] for pt in lane_lines)  # get the maximum x-coordinate from the lane points

        # define the vertices of the polygon representing the road region
        pts = np.array([
            [min_x, max_y],  # bottom left of the road region
            [max_x, max_y],  # bottom right of the road region
            [int(0.6 * width), min_y],  # top right (60% of width, min_y)
            [int(0.4 * width), min_y]  # top left (40% of width, min_y)
        ], np.int32)  # create an array of the points

        cv2.fillPoly(mask, [pts], 255)  # fill the defined polygon in the mask with white (255)
    return mask  # return the road mask

def slope(x1, y1, x2, y2): #function for slope clculation
    if x2 != x1:
        m = float(y2 - y1) / float(x2 - x1) #slope calculation
        theta = math.atan(m) #angle in radians
        return theta * (180 / np.pi) #angle in degree
    return 0

def lane_detection(frame, mask):
    edges = cv2.Canny(mask, 75, 150) #finding sharp edges in the frame
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=30,minLineLength=50, maxLineGap=20) #line segments from edgs detected

    #print(lines)
    #print(frame.shape[0])
    output_frame = frame.copy()
    lane_points = []

    if lines is not None:
        for line in lines:
            for x1, y1, x2, y2 in line: #x1,x2,y1,y2 from a line in lines array
                if y1 > frame.shape[0] * 0.4 and y2 > frame.shape[0] * 0.4: #upper 40% excluded and lower 60% frame considered
                    angle = abs(slope(x1, y1, x2, y2)) #calculate angle in degrees from slope function defined above
                    if 20 < angle < 70: #keep lines that are not too horizontal or not too steep
                        cv2.line(output_frame, (x1, y1), (x2, y2), (0, 0, 255), 2) #representing red lines in output frame
                        lane_points.append((x1, y1)) #appending points in array
                        lane_points.append((x2, y2)) #appending points in array

    return lines,output_frame, edges, lane_points #returing hough lines 4 point array and frame with red lines and edges from canny and lane_points array


def detect_objects(frame, roi_mask):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (7, 7), 1)

    edges = cv2.Canny(blurred, 30, 120)

    roi_mask = cv2.resize(roi_mask, (edges.shape[1], edges.shape[0]))
    edges = cv2.bitwise_and(edges, edges, mask=roi_mask)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
    edges = cv2.dilate(edges, kernel, iterations=1)

    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    objects = []

    for contour in contours:
        area = cv2.contourArea(contour)
        if 1000 < area < 20000:
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / float(h)
            if 0.3 < aspect_ratio < 3.0:
                cx, cy = x + w // 2, y + h // 2
                rect_area = w * h
                extent = float(area) / rect_area if rect_area > 0 else 0
                hull = cv2.convexHull(contour)
                hull_area = cv2.contourArea(hull)
                solidity = float(area) / hull_area if hull_area > 0 else 0
                perimeter = cv2.arcLength(contour, True)
                perimeter_ratio = perimeter / (w + h) if (w + h) > 0 else float('inf')

                print(f"Contour: area={area:.2f}, aspect_ratio={aspect_ratio:.2f}, "
                      f"extent={extent:.2f}, solidity={solidity:.2f}, "
                      f"perimeter_ratio={perimeter_ratio:.2f}, "
                      f"position=({cx}, {cy}), bottom_y={y+h}")

                if (extent > 0.4 and solidity > 0.6 and perimeter_ratio < 15):
                    if roi_mask[cy, cx] == 255:
                        objects.append((x, y, w, h))
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                        print(f"Detected object: ({x}, {y}, {w}, {h})")

    return frame, objects

def analyze_decision(frame, objects, traffic_light_status):
    height, width = frame.shape[:2]
    decision_text = "Move Forward"
    close_threshold = height * 0.4

    if traffic_light_status == "RED":
        decision_text = "STOP (Red Light)"
    else:
        left_bound = width // 3
        right_bound = 2 * width // 3

        left_weight, right_weight, center_weight = 0, 0, 0
        for (x, y, w, h) in objects:
            cx = x + w // 2
            bottom_y = y + h

            if bottom_y > height - close_threshold:
                decision_text = "STOP (Obstacle)"
                break

            if cx <= left_bound:
                left_weight += w * h
            elif cx >= right_bound:
                right_weight += w * h
            else:
                center_weight += w * h

        if decision_text.startswith("STOP") == False and objects:
            total_weight = left_weight + right_weight + center_weight
            if total_weight > 0:
                left_ratio = left_weight / total_weight
                right_ratio = right_weight / total_weight
                if left_ratio > 0.6:
                    decision_text = "Moving Left"
                elif right_ratio > 0.6:
                    decision_text = "Moving Right"

    color = (0, 255, 255) if "STOP" not in decision_text else (0, 0, 255)
    #print decision text on top of frame
    cv2.putText(frame, decision_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)

    #print traffic light status on the bottom of the frame
    cv2.putText(frame, f"Traffic Light: {traffic_light_status}", (50, height - 50),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)

    return frame

def calculate_and_display_fps(frame, prev_time, curr_time):
    if prev_time == 0:  #if previous time is zero (first frame)
        fps = 0  #set FPS to 0 initially
    else:
        fps = 1.0 / (curr_time - prev_time)  #calculate FPS based on time difference

    fps_text = f"fps: {fps:.2f}"  #format the FPS text to display with 2 decimal places
    cv2.putText(frame, fps_text, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)  # put FPS text on the frame

    return frame, curr_time  #return the frame and the current time for next frame

def main():
    video_path = r'path'
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print("Error: Cannot open video file.")
        return

    prev_time = 0  #initialize previous frame time

    while True:
        ret, frame = cap.read()
        if not ret:
            print("Video has ended.")
            break

        curr_time = time.time()  #get current time before processing

        frame = cv2.resize(frame, (600, 600))
        mask, boosted_gray = preprocess_frame(frame)
        lines,lane_frame, edge_frame, lane_points = lane_detection(frame, mask)
        road_mask = create_road_mask(frame, lane_points)
        result_frame, objects = detect_objects(frame, road_mask)
        traffic_light_status = detect_traffic_light(frame)
        result_frame = analyze_decision(result_frame, objects, traffic_light_status)

        #calculate and display FPS
        result_frame, prev_time = calculate_and_display_fps(result_frame, prev_time, curr_time)
        #inside the while loop, before cv2.imshow
        lane_frame = cv2.resize(lane_frame, (320, 240))
        result_frame = cv2.resize(result_frame, (320, 240))

        #inside the while loop, after processing each frame
        cv2.imshow('Lane Detection', lane_frame)
        cv2.moveWindow('Lane Detection', 320, 0)  #top-left
        cv2.imshow('Object Detection', result_frame)
        cv2.moveWindow('Object Detection', 0, 0)  #top-right (adjust based on resolution)

        key = cv2.waitKey(1)
        if key == 27 or key == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()

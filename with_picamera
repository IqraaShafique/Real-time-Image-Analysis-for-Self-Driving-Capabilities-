import cv2
import numpy as np
import math
import time
from picamera2 import Picamera2

def preprocess_frame(frame):
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    yellow_mask = cv2.inRange(hsv, (15, 30, 80), (40, 255, 255))

    h, s, v = cv2.split(hsv)
    s = cv2.equalizeHist(s)
    v = cv2.equalizeHist(v)
    boosted_hsv = cv2.merge([h, s, v])
    boosted_bgr = cv2.cvtColor(boosted_hsv, cv2.COLOR_HSV2BGR)
    boosted_gray = cv2.cvtColor(boosted_bgr, cv2.COLOR_BGR2GRAY)

    masked_gray = cv2.bitwise_and(boosted_gray, boosted_gray, mask=yellow_mask)
    adaptive_thresh = cv2.adaptiveThreshold(masked_gray, 255,
                                            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                            cv2.THRESH_BINARY, 11, 2)

    kernel = np.ones((5, 5), np.uint8)
    cleaned = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_OPEN, kernel)

    return cleaned, boosted_gray

def detect_traffic_light(frame):
    height, width = frame.shape[:2]
    roi = frame[0:int(height * 0.3), 0:int(width * 0.3)]

    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    lower_red1 = np.array([0, 70, 50])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([160, 70, 50])
    upper_red2 = np.array([180, 255, 255])

    lower_green = np.array([40, 40, 40])
    upper_green = np.array([90, 255, 255])

    lower_yellow = np.array([15, 50, 50])
    upper_yellow = np.array([35, 255, 255])

    mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask_red = cv2.bitwise_or(mask_red1, mask_red2)

    mask_green = cv2.inRange(hsv, lower_green, upper_green)
    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)

    all_masks = [mask_red, mask_green, mask_yellow]
    traffic_light_status = "NO TRAFFIC LIGHT"

    for mask in all_masks:
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 1000:
                x, y, w, h = cv2.boundingRect(contour)

                aspect_ratio = float(w) / float(h)
                if 0.8 < aspect_ratio < 1.2:
                    roi_rect = frame[y:y + h, x:x + w]
                    rect_gray = cv2.cvtColor(roi_rect, cv2.COLOR_BGR2GRAY)
                    _, thresholded = cv2.threshold(rect_gray, 100, 255, cv2.THRESH_BINARY)

                    border_pixels = thresholded[0:5, :]
                    bottom_pixels = thresholded[-5:, :]
                    left_pixels = thresholded[:, 0:5]
                    right_pixels = thresholded[:, -5:]

                    border_black = np.count_nonzero(border_pixels == 0) > 0 or \
                                   np.count_nonzero(bottom_pixels == 0) > 0 or \
                                   np.count_nonzero(left_pixels == 0) > 0 or \
                                   np.count_nonzero(right_pixels == 0) > 0

                    if border_black:
                        if np.count_nonzero(mask) > 1000:
                            if np.count_nonzero(mask_red) > 1000:
                                traffic_light_status = "RED (STOP)"
                            elif np.count_nonzero(mask_green) > 1000:
                                traffic_light_status = "GREEN (MOVE)"
                            elif np.count_nonzero(mask_yellow) > 1000:
                                traffic_light_status = "YELLOW (Be Ready)"
                            break
                else:
                    traffic_light_status = "NO TRAFFIC LIGHT"

    return traffic_light_status

def create_road_mask(frame, lane_lines):
    height, width = frame.shape[:2]
    mask = np.zeros((height, width), dtype=np.uint8)
    if lane_lines:
        min_y = int(height * 0.5)
        max_y = height

        min_x = min(pt[0] for pt in lane_lines)
        max_x = max(pt[0] for pt in lane_lines)

        pts = np.array([
            [min_x, max_y],
            [max_x, max_y],
            [int(0.6 * width), min_y],
            [int(0.4 * width), min_y]
        ], np.int32)

        cv2.fillPoly(mask, [pts], 255)
    return mask

def slope(x1, y1, x2, y2):
    if x2 != x1:
        m = float(y2 - y1) / float(x2 - x1)
        theta = math.atan(m)
        return theta * (180 / np.pi)
    return 0

def lane_detection(frame, mask):
    edges = cv2.Canny(mask, 75, 150)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=30, minLineLength=50, maxLineGap=20)

    output_frame = frame.copy()
    lane_points = []

    if lines is not None:
        for line in lines:
            for x1, y1, x2, y2 in line:
                if y1 > frame.shape[0] * 0.4 and y2 > frame.shape[0] * 0.4:
                    angle = abs(slope(x1, y1, x2, y2))
                    if 20 < angle < 70:
                        cv2.line(output_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
                        lane_points.append((x1, y1))
                        lane_points.append((x2, y2))

    return lines, output_frame, edges, lane_points

def detect_objects(frame, roi_mask):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (7, 7), 1)

    edges = cv2.Canny(blurred, 30, 120)

    roi_mask = cv2.resize(roi_mask, (edges.shape[1], edges.shape[0]))
    edges = cv2.bitwise_and(edges, edges, mask=roi_mask)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
    edges = cv2.dilate(edges, kernel, iterations=1)

    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    objects = []

    for contour in contours:
        area = cv2.contourArea(contour)
        if 1000 < area < 20000:
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / float(h)
            if 0.3 < aspect_ratio < 3.0:
                cx, cy = x + w // 2, y + h // 2
                rect_area = w * h
                extent = float(area) / rect_area if rect_area > 0 else 0
                hull = cv2.convexHull(contour)
                hull_area = cv2.contourArea(hull)
                solidity = float(area) / hull_area if hull_area > 0 else 0
                perimeter = cv2.arcLength(contour, True)
                perimeter_ratio = perimeter / (w + h) if (w + h) > 0 else float('inf')

                print(f"Contour: area={area:.2f}, aspect_ratio={aspect_ratio:.2f}, "
                      f"extent={extent:.2f}, solidity={solidity:.2f}, "
                      f"perimeter_ratio={perimeter_ratio:.2f}, "
                      f"position=({cx}, {cy}), bottom_y={y+h}")

                if (extent > 0.4 and solidity > 0.6 and perimeter_ratio < 15):
                    if roi_mask[cy, cx] == 255:
                        objects.append((x, y, w, h))
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                        print(f"Detected object: ({x}, {y}, {w}, {h})")

    return frame, objects

def analyze_decision(frame, objects, traffic_light_status):
    height, width = frame.shape[:2]
    decision_text = "Move Forward"
    close_threshold = height * 0.4

    if traffic_light_status == "RED":
        decision_text = "STOP (Red Light)"
    else:
        left_bound = width // 3
        right_bound = 2 * width // 3

        left_weight, right_weight, center_weight = 0, 0, 0
        for (x, y, w, h) in objects:
            cx = x + w // 2
            bottom_y = y + h

            if bottom_y > height - close_threshold:
                decision_text = "STOP (Obstacle)"
                break

            if cx <= left_bound:
                left_weight += w * h
            elif cx >= right_bound:
                right_weight += w * h
            else:
                center_weight += w * h

        if decision_text.startswith("STOP") == False and objects:
            total_weight = left_weight + right_weight + center_weight
            if total_weight > 0:
                left_ratio = left_weight / total_weight
                right_ratio = right_weight / total_weight
                if left_ratio > 0.6:
                    decision_text = "Moving Left"
                elif right_ratio > 0.6:
                    decision_text = "Moving Right"

    color = (0, 255, 255) if "STOP" not in decision_text else (0, 0, 255)
    cv2.putText(frame, decision_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
    cv2.putText(frame, f"Traffic Light: {traffic_light_status}", (50, height - 50),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)

    return frame

def calculate_and_display_fps(frame, prev_time, curr_time):
    if prev_time == 0:
        fps = 0
    else:
        fps = 1.0 / (curr_time - prev_time)

    fps_text = f"fps: {fps:.2f}"
    cv2.putText(frame, fps_text, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
    return frame, curr_time

def main():
    # Initialize the Pi Camera Module 3
    picam2 = Picamera2(camera_num=1)  # Use cam1
    config = picam2.create_video_configuration(main={"size": (600, 600)})
    picam2.configure(config)
    picam2.start()

    prev_time = 0  # Initialize previous frame time

    try:
        while True:
            # Capture frame from the camera
            frame = picam2.capture_array()
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Convert from RGB to BGR for OpenCV

            curr_time = time.time()  # Get current time before processing

            # Process the frame
            mask, boosted_gray = preprocess_frame(frame)
            lines, lane_frame, edge_frame, lane_points = lane_detection(frame, mask)
            road_mask = create_road_mask(frame, lane_points)
            result_frame, objects = detect_objects(frame, road_mask)
            traffic_light_status = detect_traffic_light(frame)
            result_frame = analyze_decision(result_frame, objects, traffic_light_status)

            # Calculate and display FPS
            result_frame, prev_time = calculate_and_display_fps(result_frame, prev_time, curr_time)

            # Resize and display frames
            lane_frame = cv2.resize(lane_frame, (320, 240))
            result_frame = cv2.resize(result_frame, (320, 240))

            cv2.imshow('Lane Detection', lane_frame)
            cv2.moveWindow('Lane Detection', 320, 0)  # Top-left
            cv2.imshow('Object Detection', result_frame)
            cv2.moveWindow('Object Detection', 0, 0)  # Top-right

            key = cv2.waitKey(1)
            if key == 27 or key == ord('q'):
                break

    finally:
        picam2.stop()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
